# Post Insight Data åé›†è¦ä»¶å®šç¾©æ›¸

**ä½œæˆæ—¥**: 2025-07-01  
**å¯¾è±¡**: Instagram æ–°è¦æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ï¼‹ã‚¤ãƒ³ã‚µã‚¤ãƒˆã®24æ™‚é–“ä»¥å†…è‡ªå‹•åé›†  
**ãƒ¢ãƒ‡ãƒ«**: `backend/app/models/instagram_post.py`, `backend/app/models/instagram_post_metrics.py`  

---

## ğŸ“‹ è¦ä»¶æ¦‚è¦

### ç›®çš„
24æ™‚é–“ä»¥å†…ã«æŠ•ç¨¿ã•ã‚ŒãŸæ–°è¦æŠ•ç¨¿ã‚’æ¤œå‡ºã—ã€æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã¨ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’è‡ªå‹•åé›†ã™ã‚‹ã€‚

### åé›†ã‚¿ã‚¤ãƒŸãƒ³ã‚°
- **æ¤œå‡ºé »åº¦**: 1æ—¥2å› (06:00, 18:00 JST)
- **æ¤œå‡ºç¯„å›²**: å‰å›å®Ÿè¡Œæ™‚åˆ»ä»¥é™ã®æ–°è¦æŠ•ç¨¿
- **å¯¾è±¡**: å…¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ

### åé›†å¯¾è±¡ãƒ‡ãƒ¼ã‚¿
1. **æŠ•ç¨¿åŸºæœ¬ãƒ‡ãƒ¼ã‚¿**: `instagram_post` ãƒ†ãƒ¼ãƒ–ãƒ«
2. **æŠ•ç¨¿ã‚¤ãƒ³ã‚µã‚¤ãƒˆ**: `instagram_post_metrics` ãƒ†ãƒ¼ãƒ–ãƒ«

---

## ğŸ—ï¸ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

### GitHub Actions ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
```
.github/workflows/
â””â”€â”€ new-posts-detection.yml
```

### ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
```
backend/scripts/
â”œâ”€â”€ github_actions/
â”‚   â”œâ”€â”€ new_posts_collector.py
â”‚   â””â”€â”€ shared/
â”‚       â”œâ”€â”€ post_detector.py
â”‚       â”œâ”€â”€ post_processor.py
â”‚       â””â”€â”€ execution_tracker.py
```

### å®Ÿè¡ŒçŠ¶æ…‹ç®¡ç†
```
backend/data/
â””â”€â”€ execution_state/
    â””â”€â”€ new_posts_last_execution.json
```

---

## ğŸ“ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°

### `.github/workflows/new-posts-detection.yml`

```yaml
name: New Posts Detection & Collection

on:
  schedule:
    # 1æ—¥4å›å®Ÿè¡Œ: 06:00, 12:00, 18:00, 24:00 JST (UTC -9h)
    - cron: '0 21 * * *'  # 06:00 JST
    - cron: '0 9 * * *'   # 18:00 JST
  workflow_dispatch:
    inputs:
      target_accounts:
        description: 'å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š, ç©ºã®å ´åˆã¯å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ)'
        required: false
        type: string
      check_hours_back:
        description: 'é¡åŠæ™‚é–“ (æ™‚é–“, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8)'
        required: false
        type: number
        default: 8
      force_reprocess:
        description: 'æ—¢å­˜æŠ•ç¨¿ã®å†å‡¦ç†ã‚’å¼·åˆ¶å®Ÿè¡Œ'
        required: false
        type: boolean
        default: false

jobs:
  detect-new-posts:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      FACEBOOK_APP_ID: ${{ secrets.FACEBOOK_APP_ID }}
      FACEBOOK_APP_SECRET: ${{ secrets.FACEBOOK_APP_SECRET }}
      SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r backend/requirements.txt
        
    - name: Create execution state directory
      run: |
        mkdir -p backend/data/execution_state
        
    - name: Load previous execution state
      id: load-state
      run: |
        cd backend
        if [ -f "data/execution_state/new_posts_last_execution.json" ]; then
          echo "Previous execution state found"
          cat data/execution_state/new_posts_last_execution.json
        else
          echo "No previous execution state found - first run"
        fi
        
    - name: Run new posts detection
      run: |
        cd backend
        python scripts/github_actions/new_posts_collector.py \
          --target-accounts "${{ github.event.inputs.target_accounts }}" \
          --check-hours-back ${{ github.event.inputs.check_hours_back || 8 }} \
          --force-reprocess ${{ github.event.inputs.force_reprocess }} \
          --notify-new-posts \
          --log-level INFO
          
    - name: Save execution state
      if: always()
      run: |
        cd backend
        # å®Ÿè¡ŒçŠ¶æ…‹ã®ä¿å­˜ï¼ˆæˆåŠŸãƒ»å¤±æ•—å•ã‚ãšï¼‰
        python -c "
        import json
        from datetime import datetime
        
        state = {
            'last_execution_time': datetime.now().isoformat(),
            'execution_id': '${{ github.run_id }}',
            'workflow_run': '${{ github.run_number }}',
            'trigger': '${{ github.event_name }}'
        }
        
        with open('data/execution_state/new_posts_last_execution.json', 'w') as f:
            json.dump(state, f, indent=2)
        
        print('Execution state saved')
        "
        
    - name: Commit execution state
      if: always()
      run: |
        cd backend
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/execution_state/new_posts_last_execution.json
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "Update new posts execution state [skip ci]"
          git push
        fi
        
    - name: Upload execution logs
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: new-posts-logs-${{ github.run_id }}
        path: backend/logs/github_actions/
        retention-days: 14
        
    - name: Notify on failure
      if: failure()
      run: |
        cd backend
        python scripts/github_actions/shared/notification_service.py \
          --type failure \
          --workflow "new-posts-detection" \
          --run-id "${{ github.run_id }}" \
          --message "New posts detection failed"
```

---

## ğŸ”§ ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…

### `backend/scripts/github_actions/new_posts_collector.py`

```python
#!/usr/bin/env python3
"""
New Posts Collector for GitHub Actions
24æ™‚é–“ä»¥å†…ã®æ–°è¦æŠ•ç¨¿æ¤œå‡ºãƒ»åé›†

å®Ÿè¡Œä¾‹:
    python new_posts_collector.py --notify-new-posts
    python new_posts_collector.py --target-accounts "123,456" --check-hours-back 6
    python new_posts_collector.py --force-reprocess
"""

import asyncio
import sys
import argparse
import logging
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import json
from pathlib import Path
from dataclasses import dataclass, field

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from app.core.database import get_db_sync
from app.repositories.instagram_account_repository import InstagramAccountRepository
from app.repositories.instagram_post_repository import InstagramPostRepository
from app.repositories.instagram_post_metrics_repository import InstagramPostMetricsRepository
from app.services.data_collection.instagram_api_client import InstagramAPIClient

from shared.base_collector import BaseCollector
from shared.notification_service import NotificationService
from shared.post_detector import PostDetector
from shared.post_processor import PostProcessor
from shared.execution_tracker import ExecutionTracker

@dataclass
class NewPostsResult:
    """æ–°è¦æŠ•ç¨¿åé›†çµæœ"""
    execution_id: str
    started_at: datetime
    completed_at: Optional[datetime] = None
    
    # å®Ÿè¡Œçµ±è¨ˆ
    total_accounts: int = 0
    successful_accounts: int = 0
    failed_accounts: int = 0
    
    # æ¤œå‡ºçµ±è¨ˆ
    total_posts_checked: int = 0
    new_posts_found: int = 0
    new_posts_saved: int = 0
    insights_collected: int = 0
    
    # APIä½¿ç”¨çµ±è¨ˆ
    api_calls_made: int = 0
    
    # ã‚¨ãƒ©ãƒ¼æƒ…å ±
    errors: List[str] = field(default_factory=list)
    account_results: List[Dict] = field(default_factory=list)
    new_posts_details: List[Dict] = field(default_factory=list)

class NewPostsCollector(BaseCollector):
    """æ–°è¦æŠ•ç¨¿åé›†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        super().__init__("new_posts")
        self.notification = NotificationService()
        self.post_detector = PostDetector()
        self.post_processor = PostProcessor()
        self.execution_tracker = ExecutionTracker()
        
    async def detect_and_collect(
        self,
        target_accounts: Optional[List[str]] = None,
        check_hours_back: int = 8,
        force_reprocess: bool = False
    ) -> NewPostsResult:
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†: æ–°è¦æŠ•ç¨¿æ¤œå‡ºãƒ»åé›†"""
        
        execution_id = f"new_posts_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        result = NewPostsResult(
            execution_id=execution_id,
            started_at=datetime.now()
        )
        
        try:
            self.logger.info(f"ğŸš€ New posts detection started: {execution_id}")
            
            # å‰å›å®Ÿè¡Œæ™‚åˆ»ã®å–å¾—
            last_execution_time = self.execution_tracker.get_last_execution_time()
            
            # ãƒã‚§ãƒƒã‚¯é–‹å§‹æ™‚åˆ»ã®æ±ºå®š
            if last_execution_time and not force_reprocess:
                check_from = last_execution_time
                self.logger.info(f"ğŸ“… Checking posts since last execution: {check_from}")
            else:
                check_from = datetime.now() - timedelta(hours=check_hours_back)
                self.logger.info(f"ğŸ“… Checking posts from {check_hours_back} hours back: {check_from}")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šåˆæœŸåŒ–
            await self._init_database()
            
            # å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—
            accounts = await self._get_target_accounts(target_accounts)
            result.total_accounts = len(accounts)
            
            self.logger.info(f"ğŸ¯ Target accounts: {result.total_accounts}")
            
            # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ¥å‡¦ç†
            for account in accounts:
                account_result = await self._detect_account_new_posts(
                    account, check_from, force_reprocess
                )
                
                result.account_results.append(account_result)
                
                if account_result['success']:
                    result.successful_accounts += 1
                    result.total_posts_checked += account_result['posts_checked']
                    result.new_posts_found += account_result['new_posts_found']
                    result.new_posts_saved += account_result['new_posts_saved']
                    result.insights_collected += account_result['insights_collected']
                    result.api_calls_made += account_result['api_calls']
                    
                    # æ–°è¦æŠ•ç¨¿è©³ç´°ã‚’è¨˜éŒ²
                    for post_detail in account_result['new_posts_details']:
                        result.new_posts_details.append(post_detail)
                else:
                    result.failed_accounts += 1
                    result.errors.append(
                        f"Account {account_result['username']}: {account_result['error']}"
                    )
                
                # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–“ã®å¾…æ©Ÿï¼ˆAPIåˆ¶é™å¯¾å¿œï¼‰
                await asyncio.sleep(3)
            
            result.completed_at = datetime.now()
            
            # å®Ÿè¡Œæ™‚åˆ»ã®æ›´æ–°
            self.execution_tracker.update_last_execution_time(result.started_at)
            
            # å®Ÿè¡Œçµæœãƒ­ã‚°
            duration = (result.completed_at - result.started_at).total_seconds()
            success_rate = (result.successful_accounts / result.total_accounts * 100) if result.total_accounts > 0 else 0
            
            self.logger.info(f"âœ… Detection completed in {duration:.1f}s")
            self.logger.info(f"ğŸ“Š Success rate: {success_rate:.1f}% ({result.successful_accounts}/{result.total_accounts})")
            self.logger.info(f"ğŸ†• New posts found: {result.new_posts_found}")
            self.logger.info(f"ğŸ’¾ New posts saved: {result.new_posts_saved}")
            self.logger.info(f"ğŸ“ˆ Insights collected: {result.insights_collected}")
            self.logger.info(f"ğŸ“ API calls made: {result.api_calls_made}")
            
            return result
            
        except Exception as e:
            result.completed_at = datetime.now()
            error_msg = f"Critical error in new posts detection: {str(e)}"
            result.errors.append(error_msg)
            self.logger.error(error_msg, exc_info=True)
            return result
            
        finally:
            await self._cleanup_database()

    async def _detect_account_new_posts(
        self, 
        account, 
        check_from: datetime,
        force_reprocess: bool
    ) -> Dict[str, Any]:
        """å˜ä¸€ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æ–°è¦æŠ•ç¨¿æ¤œå‡º"""
        
        account_result = {
            'account_id': account.id,
            'instagram_user_id': account.instagram_user_id,
            'username': account.username,
            'success': False,
            'posts_checked': 0,
            'new_posts_found': 0,
            'new_posts_saved': 0,
            'insights_collected': 0,
            'api_calls': 0,
            'new_posts_details': [],
            'error': None
        }
        
        try:
            self.logger.info(f"ğŸ” Checking account: {account.username}")
            
            async with InstagramAPIClient() as api_client:
                # æœ€æ–°æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæœ€å¤§50ä»¶ï¼‰
                recent_posts = await self._fetch_recent_posts(api_client, account, limit=50)
                account_result['api_calls'] += 1
                account_result['posts_checked'] = len(recent_posts)
                
                # æ–°è¦æŠ•ç¨¿ã®æ¤œå‡º
                new_posts = await self.post_detector.detect_new_posts(
                    recent_posts, 
                    check_from, 
                    account.id,
                    force_reprocess
                )
                account_result['new_posts_found'] = len(new_posts)
                
                if new_posts:
                    self.logger.info(f"ğŸ†• Found {len(new_posts)} new posts for {account.username}")
                    
                    # æ–°è¦æŠ•ç¨¿ã®å‡¦ç†
                    for post_data in new_posts:
                        try:
                            # æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                            saved_post = await self.post_processor.save_post_data(
                                account.id, post_data
                            )
                            
                            if saved_post:
                                account_result['new_posts_saved'] += 1
                                
                                # æŠ•ç¨¿ã‚¤ãƒ³ã‚µã‚¤ãƒˆåé›†
                                insights = await api_client.get_post_insights(
                                    post_data['id'],
                                    account.access_token_encrypted,
                                    post_data.get('media_type', 'IMAGE')
                                )
                                account_result['api_calls'] += 1
                                
                                if insights:
                                    await self.post_processor.save_post_insights(
                                        saved_post.id, insights
                                    )
                                    account_result['insights_collected'] += 1
                                
                                # æ–°è¦æŠ•ç¨¿è©³ç´°ã‚’è¨˜éŒ²
                                post_detail = {
                                    'account_username': account.username,
                                    'post_id': post_data['id'],
                                    'media_type': post_data.get('media_type'),
                                    'timestamp': post_data.get('timestamp'),
                                    'permalink': post_data.get('permalink'),
                                    'caption_preview': (post_data.get('caption', '') or '')[:100] + '...' if post_data.get('caption') else None,
                                    'insights_collected': insights is not None
                                }
                                account_result['new_posts_details'].append(post_detail)
                                
                                self.logger.info(
                                    f"âœ… Saved new post: {post_data['id']} "
                                    f"({post_data.get('media_type')}) "
                                    f"- insights: {'âœ“' if insights else 'âœ—'}"
                                )
                                
                                # APIåˆ¶é™å¯¾å¿œï¼ˆæŠ•ç¨¿é–“ã®å¾…æ©Ÿï¼‰
                                await asyncio.sleep(2)
                                
                        except Exception as e:
                            self.logger.error(f"âŒ Failed to process new post {post_data['id']}: {e}")
                            continue
                else:
                    self.logger.info(f"ğŸ“­ No new posts found for {account.username}")
                
                account_result['success'] = True
                
        except Exception as e:
            account_result['error'] = str(e)
            self.logger.error(f"âŒ Failed to check account {account.username}: {e}")
        
        return account_result

    async def _fetch_recent_posts(
        self, 
        api_client: InstagramAPIClient, 
        account, 
        limit: int = 50
    ) -> List[Dict]:
        """æœ€æ–°æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        
        url = api_client.config.get_user_media_url(account.instagram_user_id)
        
        params = {
            'fields': 'id,media_type,permalink,caption,timestamp,like_count,comments_count,media_url,thumbnail_url',
            'access_token': account.access_token_encrypted,
            'limit': min(limit, 100)  # APIåˆ¶é™ã«åˆã‚ã›ã‚‹
        }
        
        try:
            response = await api_client._make_request(url, params)
            posts = response.get('data', [])
            
            self.logger.debug(f"Retrieved {len(posts)} recent posts for {account.username}")
            return posts
            
        except Exception as e:
            self.logger.error(f"Failed to fetch recent posts for {account.username}: {e}")
            return []

# CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
async def main():
    parser = argparse.ArgumentParser(description='New Posts Collector')
    parser.add_argument('--target-accounts', help='å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)')
    parser.add_argument('--check-hours-back', type=int, default=8, help='é¡åŠæ™‚é–“ (æ™‚é–“)')
    parser.add_argument('--force-reprocess', action='store_true', help='æ—¢å­˜æŠ•ç¨¿ã®å†å‡¦ç†ã‚’å¼·åˆ¶å®Ÿè¡Œ')
    parser.add_argument('--notify-new-posts', action='store_true', help='æ–°è¦æŠ•ç¨¿ã‚’Slacké€šçŸ¥')
    parser.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'], 
                       default='INFO', help='ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«')
    
    args = parser.parse_args()
    
    # å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®è¨­å®š
    target_accounts = None
    if args.target_accounts:
        target_accounts = [acc.strip() for acc in args.target_accounts.split(',') if acc.strip()]
    
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
    logging.getLogger().setLevel(getattr(logging, args.log_level))
    
    # æ¤œå‡ºãƒ»åé›†å®Ÿè¡Œ
    collector = NewPostsCollector()
    result = await collector.detect_and_collect(
        target_accounts=target_accounts,
        check_hours_back=args.check_hours_back,
        force_reprocess=args.force_reprocess
    )
    
    # çµæœè¡¨ç¤º
    print(f"\n{'='*60}")
    print("ğŸ†• NEW POSTS DETECTION RESULT")
    print(f"{'='*60}")
    print(f"ğŸ¯ Accounts: {result.successful_accounts}/{result.total_accounts} succeeded")
    print(f"ğŸ“Š Posts checked: {result.total_posts_checked}")
    print(f"ğŸ†• New posts found: {result.new_posts_found}")
    print(f"ğŸ’¾ New posts saved: {result.new_posts_saved}")
    print(f"ğŸ“ˆ Insights collected: {result.insights_collected}")
    print(f"ğŸ“ API calls: {result.api_calls_made}")
    
    # æ–°è¦æŠ•ç¨¿è©³ç´°è¡¨ç¤º
    if result.new_posts_details:
        print(f"\nğŸ“ New Posts Details:")
        for post in result.new_posts_details[:10]:  # æœ€åˆã®10ä»¶ã®ã¿è¡¨ç¤º
            print(f"   @{post['account_username']}: {post['media_type']} - {post['insights_collected'] and 'ğŸ“Š' or 'âŒ'}")
    
    if result.errors:
        print(f"\nâŒ Errors ({len(result.errors)}):")
        for error in result.errors[:5]:
            print(f"   {error}")
    
    duration = (result.completed_at - result.started_at).total_seconds()
    print(f"\nâ±ï¸ Duration: {duration:.1f}s")
    print(f"{'='*60}")
    
    # Slacké€šçŸ¥ï¼ˆæ–°è¦æŠ•ç¨¿ãŒã‚ã£ãŸå ´åˆã®ã¿ï¼‰
    if args.notify_new_posts and result.new_posts_found > 0:
        await collector.notification.send_new_posts_notification(result)
    
    # å¤±æ•—ãŒã‚ã£ãŸå ´åˆã¯ exit code 1
    return 1 if result.failed_accounts > 0 else 0

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
```

---

## ğŸ”§ æ”¯æ´ã‚¯ãƒ©ã‚¹å®Ÿè£…

### `backend/scripts/github_actions/shared/post_detector.py`

```python
"""
Post Detector
æ–°è¦æŠ•ç¨¿æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯
"""

from datetime import datetime
from typing import List, Dict, Any
import logging

from app.repositories.instagram_post_repository import InstagramPostRepository

class PostDetector:
    """æŠ•ç¨¿æ¤œå‡ºã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    async def detect_new_posts(
        self,
        api_posts: List[Dict],
        check_from: datetime,
        account_id: str,
        force_reprocess: bool = False
    ) -> List[Dict]:
        """æ–°è¦æŠ•ç¨¿æ¤œå‡º"""
        
        new_posts = []
        
        for post in api_posts:
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒã‚§ãƒƒã‚¯
            if not self._is_within_timeframe(post, check_from):
                continue
            
            # æ—¢å­˜æŠ•ç¨¿ãƒã‚§ãƒƒã‚¯ï¼ˆforce_reprocessã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            if not force_reprocess:
                if await self._post_exists_in_db(post['id']):
                    continue
            
            new_posts.append(post)
        
        return new_posts
    
    def _is_within_timeframe(self, post: Dict, check_from: datetime) -> bool:
        """æŠ•ç¨¿ãŒæŒ‡å®šæ™‚åˆ»ä»¥é™ã‹ãƒã‚§ãƒƒã‚¯"""
        timestamp_str = post.get('timestamp', '')
        if not timestamp_str:
            return False
        
        try:
            # ISO 8601 format: "2025-07-01T10:30:45+0000"
            post_datetime = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
            return post_datetime >= check_from
        except ValueError:
            self.logger.warning(f"Invalid timestamp format: {timestamp_str}")
            return False
    
    async def _post_exists_in_db(self, instagram_post_id: str) -> bool:
        """æŠ•ç¨¿ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        # æ³¨æ„: ã“ã®å®Ÿè£…ã§ã¯æ¯å›DBã‚¢ã‚¯ã‚»ã‚¹ãŒç™ºç”Ÿã™ã‚‹ãŸã‚ã€
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯äº‹å‰ã«æ—¢å­˜æŠ•ç¨¿IDãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¦
        # ãƒ¡ãƒ¢ãƒªä¸Šã§ãƒã‚§ãƒƒã‚¯ã™ã‚‹æ–¹ãŒåŠ¹ç‡çš„
        
        from app.core.database import get_db_sync
        db = get_db_sync()
        try:
            post_repo = InstagramPostRepository(db)
            existing_post = await post_repo.get_by_instagram_post_id(instagram_post_id)
            return existing_post is not None
        finally:
            db.close()
```

### `backend/scripts/github_actions/shared/execution_tracker.py`

```python
"""
Execution Tracker
å®Ÿè¡ŒçŠ¶æ…‹ç®¡ç†
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Optional
import logging

class ExecutionTracker:
    """å®Ÿè¡ŒçŠ¶æ…‹è¿½è·¡ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.state_file = Path(__file__).parent.parent.parent.parent / "data" / "execution_state" / "new_posts_last_execution.json"
        self.state_file.parent.mkdir(parents=True, exist_ok=True)
    
    def get_last_execution_time(self) -> Optional[datetime]:
        """å‰å›å®Ÿè¡Œæ™‚åˆ»å–å¾—"""
        try:
            if self.state_file.exists():
                with open(self.state_file, 'r') as f:
                    state = json.load(f)
                
                last_time_str = state.get('last_execution_time')
                if last_time_str:
                    return datetime.fromisoformat(last_time_str)
            
            return None
            
        except Exception as e:
            self.logger.warning(f"Failed to load execution state: {e}")
            return None
    
    def update_last_execution_time(self, execution_time: datetime):
        """å®Ÿè¡Œæ™‚åˆ»æ›´æ–°"""
        try:
            state = {
                'last_execution_time': execution_time.isoformat(),
                'updated_at': datetime.now().isoformat()
            }
            
            with open(self.state_file, 'w') as f:
                json.dump(state, f, indent=2)
            
            self.logger.info(f"Execution state updated: {execution_time}")
            
        except Exception as e:
            self.logger.error(f"Failed to update execution state: {e}")
```

---

## ğŸ”” é€šçŸ¥æ©Ÿèƒ½

### æ–°è¦æŠ•ç¨¿é€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¾‹
```json
{
  "text": "ğŸ†• New Instagram Posts Detected!",
  "attachments": [
    {
      "color": "good",
      "fields": [
        {
          "title": "Summary",
          "value": "ğŸ“ 3 new posts found across 2 accounts",
          "short": false
        },
        {
          "title": "@username1",
          "value": "2 new posts (CAROUSEL_ALBUM)",
          "short": true
        },
        {
          "title": "@username2", 
          "value": "1 new post (VIDEO)",
          "short": true
        }
      ],
      "footer": "Instagram Posts Monitor",
      "ts": 1625123456
    }
  ]
}
```

---

## ğŸ“Š æ³¨æ„ç‚¹ãƒ»åˆ¶ç´„äº‹é …

### 1. StoryæŠ•ç¨¿ã®åˆ¶é™
```python
# Stories ã¯24æ™‚é–“ã§æ¶ˆå¤±ã™ã‚‹ãŸã‚ã€APIçµŒç”±ã§ã¯å–å¾—å›°é›£
# é€šå¸¸ã®æŠ•ç¨¿ï¼ˆãƒ•ã‚£ãƒ¼ãƒ‰æŠ•ç¨¿ï¼‰ã®ã¿ãŒå¯¾è±¡
```

### 2. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç²¾åº¦
```python
# Instagram APIã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯ç§’å˜ä½
# åŒä¸€ç§’å†…ã®è¤‡æ•°æŠ•ç¨¿ã¯æ¤œå‡ºé †åºãŒä¸å®š
post_datetime = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
```

### 3. APIåˆ¶é™ç®¡ç†
```python
# é »ç¹ãªå®Ÿè¡Œã«ã‚ˆã‚‹APIåˆ¶é™å¯¾ç­–
await asyncio.sleep(2)  # æŠ•ç¨¿é–“å¾…æ©Ÿ
await asyncio.sleep(3)  # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–“å¾…æ©Ÿ

# 1å›ã®å®Ÿè¡Œã§ã®APIä½¿ç”¨é‡åˆ¶å¾¡
limit = min(50, 100)  # æœ€æ–°50ä»¶ã®ã¿ãƒã‚§ãƒƒã‚¯
```

### 4. ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§
```python
# é‡è¤‡æŠ•ç¨¿ã®é˜²æ­¢
if await self._post_exists_in_db(post['id']):
    continue

# ã‚¨ãƒ©ãƒ¼æ™‚ã®éƒ¨åˆ†çš„å¤±æ•—è¨±å®¹
try:
    # æŠ•ç¨¿å‡¦ç†
except Exception as e:
    continue  # ä»–ã®æŠ•ç¨¿å‡¦ç†ã¯ç¶™ç¶š
```

### 5. å®Ÿè¡ŒçŠ¶æ…‹ç®¡ç†
```python
# GitHub Actions ã§ã®å®Ÿè¡ŒçŠ¶æ…‹æ°¸ç¶šåŒ–
# data/execution_state/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Gitã«ã‚³ãƒŸãƒƒãƒˆ
git add data/execution_state/new_posts_last_execution.json
git commit -m "Update execution state [skip ci]"
```

---

## âœ… å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Phase 1: åŸºæœ¬å®Ÿè£…
- [ ] ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
- [ ] ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…
- [ ] æ–°è¦æŠ•ç¨¿æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯
- [ ] å®Ÿè¡ŒçŠ¶æ…‹ç®¡ç†æ©Ÿèƒ½

### Phase 2: ãƒ‡ãƒ¼ã‚¿åé›†å¼·åŒ–
- [ ] æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜æ©Ÿèƒ½
- [ ] ã‚¤ãƒ³ã‚µã‚¤ãƒˆåé›†æ©Ÿèƒ½
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
- [ ] APIåˆ¶é™å¯¾å¿œ

### Phase 3: é€šçŸ¥ãƒ»ç›£è¦–
- [ ] æ–°è¦æŠ•ç¨¿Slacké€šçŸ¥
- [ ] å®Ÿè¡Œçµæœãƒ­ã‚°
- [ ] éšœå®³æ™‚ã‚¢ãƒ©ãƒ¼ãƒˆ
- [ ] å®Ÿè¡Œçµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ

### Phase 4: é‹ç”¨æœ€é©åŒ–
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- [ ] ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
- [ ] è‡ªå‹•å¾©æ—§æ©Ÿèƒ½
- [ ] ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

---

**çµè«–**: ã“ã®è¦ä»¶å®šç¾©ã«ã‚ˆã‚Šã€24æ™‚é–“ä»¥å†…ã®æ–°è¦æŠ•ç¨¿ã‚’åŠ¹ç‡çš„ã«æ¤œå‡ºãƒ»åé›†ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚1æ—¥2å›ã®å®šæœŸå®Ÿè¡Œã«ã‚ˆã‚Šã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ã‚’ä¿ã¡ãªãŒã‚‰APIåˆ¶é™å†…ã§å®‰å®šã—ãŸé‹ç”¨ãŒå¯èƒ½ã§ã™ã€‚