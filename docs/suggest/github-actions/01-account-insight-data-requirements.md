# Account Insight Data åé›†è¦ä»¶å®šç¾©æ›¸

**ä½œæˆæ—¥**: 2025-07-01  
**å¯¾è±¡**: Instagram Daily Stats (ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«) ã®æ¯æ—¥è‡ªå‹•åé›†  
**ãƒ¢ãƒ‡ãƒ«**: `backend/app/models/instagram_daily_stats.py`  

---

## ğŸ“‹ è¦ä»¶æ¦‚è¦

### ç›®çš„
å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æ—¥æ¬¡çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’æ¯æ—¥è‡ªå‹•åé›†ã—ã€`instagram_daily_stats` ãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ ã™ã‚‹ã€‚

### åé›†å¯¾è±¡
- **å…¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ**: `instagram_accounts.is_active = true`
- **å®Ÿè¡Œé »åº¦**: æ¯æ—¥1å›
- **ãƒ‡ãƒ¼ã‚¿å†…å®¹**: åŸºæœ¬ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ + æŠ•ç¨¿é›†ç´„ãƒ‡ãƒ¼ã‚¿

---

## ğŸ—ï¸ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

### GitHub Actions ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
```
.github/workflows/
â””â”€â”€ daily-account-insights.yml
```

### ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
```
backend/scripts/
â”œâ”€â”€ github_actions/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ account_insights_collector.py
â”‚   â””â”€â”€ shared/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base_collector.py
â”‚       â”œâ”€â”€ notification_service.py
â”‚       â””â”€â”€ error_handler.py
```

### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
```
backend/config/
â””â”€â”€ github_actions/
    â””â”€â”€ account_insights_config.py
```

---

## ğŸ“ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°

### `.github/workflows/daily-account-insights.yml`

```yaml
name: Daily Account Insights Collection

on:
  schedule:
    # æ¯æ—¥ 09:00 JST (UTC 00:00)
    - cron: '0 0 * * *'
  workflow_dispatch:
    inputs:
      target_date:
        description: 'å¯¾è±¡æ—¥ä»˜ (YYYY-MM-DD, ç©ºã®å ´åˆã¯ä»Šæ—¥)'
        required: false
        type: string
      target_accounts:
        description: 'å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š, ç©ºã®å ´åˆã¯å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ)'
        required: false
        type: string
      force_update:
        description: 'æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®å¼·åˆ¶ä¸Šæ›¸ã'
        required: false
        type: boolean
        default: false

jobs:
  collect-account-insights:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      FACEBOOK_APP_ID: ${{ secrets.FACEBOOK_APP_ID }}
      FACEBOOK_APP_SECRET: ${{ secrets.FACEBOOK_APP_SECRET }}
      SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r backend/requirements.txt
        
    - name: Validate environment
      run: |
        cd backend
        python -c "
        import os
        required_vars = ['DATABASE_URL', 'FACEBOOK_APP_ID', 'FACEBOOK_APP_SECRET']
        missing = [var for var in required_vars if not os.getenv(var)]
        if missing:
            print(f'Missing required environment variables: {missing}')
            exit(1)
        print('Environment validation passed')
        "
        
    - name: Run account insights collection
      run: |
        cd backend
        python scripts/github_actions/account_insights_collector.py \
          --target-date "${{ github.event.inputs.target_date }}" \
          --target-accounts "${{ github.event.inputs.target_accounts }}" \
          --force-update ${{ github.event.inputs.force_update }} \
          --notify-slack \
          --log-level INFO
          
    - name: Upload execution logs
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: account-insights-logs-${{ github.run_id }}
        path: backend/logs/github_actions/
        retention-days: 30
        
    - name: Notify on failure
      if: failure()
      run: |
        cd backend
        python scripts/github_actions/shared/notification_service.py \
          --type failure \
          --workflow "daily-account-insights" \
          --run-id "${{ github.run_id }}" \
          --message "Account insights collection failed"
```

---

## ğŸ”§ ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…

### `backend/scripts/github_actions/account_insights_collector.py`

```python
#!/usr/bin/env python3
"""
Account Insights Collector for GitHub Actions
ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã‚¤ãƒ³ã‚µã‚¤ãƒˆï¼ˆDaily Statsï¼‰ã®è‡ªå‹•åé›†

å®Ÿè¡Œä¾‹:
    python account_insights_collector.py --notify-slack
    python account_insights_collector.py --target-date 2025-07-01
    python account_insights_collector.py --target-accounts "123,456" --force-update
"""

import asyncio
import sys
import argparse
import logging
import os
from datetime import datetime, date, timedelta
from typing import List, Dict, Any, Optional
import json
from pathlib import Path
from dataclasses import dataclass, field

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from app.core.database import get_db_sync
from app.repositories.instagram_account_repository import InstagramAccountRepository
from app.repositories.instagram_daily_stats_repository import InstagramDailyStatsRepository
from app.services.data_collection.instagram_api_client import InstagramAPIClient

from shared.base_collector import BaseCollector
from shared.notification_service import NotificationService
from shared.error_handler import ErrorHandler

@dataclass
class AccountInsightsResult:
    """ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚¤ãƒ³ã‚µã‚¤ãƒˆåé›†çµæœ"""
    execution_id: str
    target_date: date
    started_at: datetime
    completed_at: Optional[datetime] = None
    
    # å®Ÿè¡Œçµ±è¨ˆ
    total_accounts: int = 0
    successful_accounts: int = 0
    failed_accounts: int = 0
    
    # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
    stats_created: int = 0
    stats_updated: int = 0
    api_calls_made: int = 0
    
    # ã‚¨ãƒ©ãƒ¼æƒ…å ±
    errors: List[str] = field(default_factory=list)
    account_results: List[Dict] = field(default_factory=list)

class AccountInsightsCollector(BaseCollector):
    """ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚¤ãƒ³ã‚µã‚¤ãƒˆåé›†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        super().__init__("account_insights")
        self.notification = NotificationService()
        self.error_handler = ErrorHandler()
        
    async def collect_daily_stats(
        self,
        target_date: date,
        target_accounts: Optional[List[str]] = None,
        force_update: bool = False
    ) -> AccountInsightsResult:
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†: æ—¥æ¬¡çµ±è¨ˆãƒ‡ãƒ¼ã‚¿åé›†"""
        
        execution_id = f"account_insights_{target_date.strftime('%Y%m%d')}_{datetime.now().strftime('%H%M%S')}"
        result = AccountInsightsResult(
            execution_id=execution_id,
            target_date=target_date,
            started_at=datetime.now()
        )
        
        try:
            self.logger.info(f"ğŸš€ Account insights collection started: {execution_id}")
            self.logger.info(f"ğŸ“… Target date: {target_date}")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šåˆæœŸåŒ–
            await self._init_database()
            
            # å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—
            accounts = await self._get_target_accounts(target_accounts)
            result.total_accounts = len(accounts)
            
            self.logger.info(f"ğŸ¯ Target accounts: {result.total_accounts}")
            
            # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ¥å‡¦ç†
            for account in accounts:
                account_result = await self._collect_account_stats(
                    account, target_date, force_update
                )
                
                result.account_results.append(account_result)
                
                if account_result['success']:
                    result.successful_accounts += 1
                    if account_result['created']:
                        result.stats_created += 1
                    else:
                        result.stats_updated += 1
                    result.api_calls_made += account_result['api_calls']
                else:
                    result.failed_accounts += 1
                    result.errors.append(
                        f"Account {account_result['username']}: {account_result['error']}"
                    )
                
                # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–“ã®å¾…æ©Ÿï¼ˆAPIåˆ¶é™å¯¾å¿œï¼‰
                await asyncio.sleep(5)
            
            result.completed_at = datetime.now()
            
            # å®Ÿè¡Œçµæœãƒ­ã‚°
            duration = (result.completed_at - result.started_at).total_seconds()
            success_rate = (result.successful_accounts / result.total_accounts * 100) if result.total_accounts > 0 else 0
            
            self.logger.info(f"âœ… Collection completed in {duration:.1f}s")
            self.logger.info(f"ğŸ“Š Success rate: {success_rate:.1f}% ({result.successful_accounts}/{result.total_accounts})")
            self.logger.info(f"ğŸ“ Stats created: {result.stats_created}, updated: {result.stats_updated}")
            self.logger.info(f"ğŸ“ API calls made: {result.api_calls_made}")
            
            return result
            
        except Exception as e:
            result.completed_at = datetime.now()
            error_msg = f"Critical error in account insights collection: {str(e)}"
            result.errors.append(error_msg)
            self.logger.error(error_msg, exc_info=True)
            return result
            
        finally:
            await self._cleanup_database()

    async def _collect_account_stats(
        self, 
        account, 
        target_date: date, 
        force_update: bool
    ) -> Dict[str, Any]:
        """å˜ä¸€ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿åé›†"""
        
        account_result = {
            'account_id': account.id,
            'instagram_user_id': account.instagram_user_id,
            'username': account.username,
            'success': False,
            'created': False,
            'api_calls': 0,
            'error': None
        }
        
        try:
            self.logger.info(f"ğŸ”„ Processing account: {account.username}")
            
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
            daily_stats_repo = InstagramDailyStatsRepository(self.db)
            existing_stats = await daily_stats_repo.get_by_specific_date(account.id, target_date)
            
            if existing_stats and not force_update:
                self.logger.info(f"â­ï¸ Skipping {account.username}: stats already exist for {target_date}")
                account_result['success'] = True
                account_result['created'] = False
                return account_result
            
            # APIçµŒç”±ã§ãƒ‡ãƒ¼ã‚¿åé›†
            async with InstagramAPIClient() as api_client:
                # 1. åŸºæœ¬ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
                basic_data = await api_client.get_basic_account_data(
                    account.instagram_user_id,
                    account.access_token_encrypted
                )
                account_result['api_calls'] += 1
                
                # 2. å…¨æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿å–å¾—
                all_posts = await self._fetch_all_posts(api_client, account)
                account_result['api_calls'] += 1
                
                # 3. æŒ‡å®šæ—¥ã®æŠ•ç¨¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                target_posts = self._filter_posts_by_date(all_posts, target_date)
                
                # 4. çµ±è¨ˆãƒ‡ãƒ¼ã‚¿è¨ˆç®—
                stats_data = await self._calculate_daily_stats(
                    account.id,
                    target_date,
                    basic_data,
                    target_posts
                )
                
                # 5. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
                if existing_stats:
                    # æ›´æ–°
                    await daily_stats_repo.update(existing_stats.id, stats_data)
                    account_result['created'] = False
                    self.logger.info(f"âœï¸ Updated stats for {account.username}: {target_date}")
                else:
                    # æ–°è¦ä½œæˆ
                    await daily_stats_repo.create(stats_data)
                    account_result['created'] = True
                    self.logger.info(f"âœ¨ Created stats for {account.username}: {target_date}")
                
                account_result['success'] = True
                
        except Exception as e:
            account_result['error'] = str(e)
            self.logger.error(f"âŒ Failed to process account {account.username}: {e}")
        
        return account_result

    async def _fetch_all_posts(self, api_client: InstagramAPIClient, account) -> List[Dict]:
        """å…¨æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        url = api_client.config.get_user_media_url(account.instagram_user_id)
        all_posts = []
        next_url = None
        page_count = 0
        max_pages = 20  # åˆ¶é™ã‚’è¨­ã‘ã¦éåº¦ãªAPIä½¿ç”¨ã‚’é˜²ã
        
        while page_count < max_pages:
            page_count += 1
            
            params = {
                'fields': 'id,media_type,timestamp,like_count,comments_count',
                'access_token': account.access_token_encrypted,
                'limit': 100
            }
            
            try:
                if next_url:
                    response = await api_client._make_request(next_url, {})
                else:
                    response = await api_client._make_request(url, params)
                
                posts = response.get('data', [])
                all_posts.extend(posts)
                
                self.logger.debug(f"Page {page_count}: {len(posts)} posts retrieved")
                
                # æ¬¡ãƒšãƒ¼ã‚¸ã®ç¢ºèª
                paging = response.get('paging', {})
                next_url = paging.get('next')
                
                if not next_url:
                    break
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ
                await asyncio.sleep(1)
                
            except Exception as e:
                self.logger.warning(f"Error fetching posts page {page_count}: {e}")
                break
        
        self.logger.info(f"Retrieved {len(all_posts)} total posts for {account.username}")
        return all_posts

    def _filter_posts_by_date(self, posts: List[Dict], target_date: date) -> List[Dict]:
        """æŒ‡å®šæ—¥ã®æŠ•ç¨¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        filtered_posts = []
        
        for post in posts:
            timestamp = post.get('timestamp', '')
            if timestamp:
                try:
                    post_date_str = timestamp.split('T')[0]
                    post_date = date.fromisoformat(post_date_str)
                    if post_date == target_date:
                        filtered_posts.append(post)
                except:
                    continue
        
        self.logger.debug(f"Filtered to {len(filtered_posts)} posts for {target_date}")
        return filtered_posts

    async def _calculate_daily_stats(
        self,
        account_id: str,
        target_date: date,
        basic_data: Dict,
        target_posts: List[Dict]
    ) -> Dict[str, Any]:
        """æ—¥æ¬¡çµ±è¨ˆãƒ‡ãƒ¼ã‚¿è¨ˆç®—"""
        
        # æŠ•ç¨¿æ•°ãƒ»ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆè¨ˆç®—
        posts_count = len(target_posts)
        total_likes = sum(p.get('like_count', 0) for p in target_posts)
        total_comments = sum(p.get('comments_count', 0) for p in target_posts)
        
        avg_likes_per_post = total_likes / posts_count if posts_count > 0 else 0.0
        avg_comments_per_post = total_comments / posts_count if posts_count > 0 else 0.0
        
        # ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—åˆ†å¸ƒ
        media_types = {}
        for post in target_posts:
            media_type = post.get('media_type', 'UNKNOWN')
            media_types[media_type] = media_types.get(media_type, 0) + 1
        
        return {
            'account_id': account_id,
            'stats_date': target_date,
            'followers_count': basic_data.get('followers_count', 0),
            'following_count': basic_data.get('follows_count', 0),
            'media_count': basic_data.get('media_count', 0),
            'posts_count': posts_count,
            'total_likes': total_likes,
            'total_comments': total_comments,
            'media_type_distribution': json.dumps(media_types),
            'data_sources': json.dumps(['github_actions_daily_collection'])
        }

# CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
async def main():
    parser = argparse.ArgumentParser(description='Account Insights Collector')
    parser.add_argument('--target-date', help='å¯¾è±¡æ—¥ä»˜ (YYYY-MM-DD)')
    parser.add_argument('--target-accounts', help='å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)')
    parser.add_argument('--force-update', action='store_true', help='æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®å¼·åˆ¶ä¸Šæ›¸ã')
    parser.add_argument('--notify-slack', action='store_true', help='Slacké€šçŸ¥ã‚’é€ä¿¡')
    parser.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'], 
                       default='INFO', help='ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«')
    
    args = parser.parse_args()
    
    # å¯¾è±¡æ—¥ä»˜ã®è¨­å®š
    if args.target_date:
        try:
            target_date = date.fromisoformat(args.target_date)
        except ValueError:
            print(f"âŒ Invalid date format: {args.target_date}")
            return 1
    else:
        target_date = date.today()
    
    # å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®è¨­å®š
    target_accounts = None
    if args.target_accounts:
        target_accounts = [acc.strip() for acc in args.target_accounts.split(',') if acc.strip()]
    
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
    logging.getLogger().setLevel(getattr(logging, args.log_level))
    
    # åé›†å®Ÿè¡Œ
    collector = AccountInsightsCollector()
    result = await collector.collect_daily_stats(
        target_date=target_date,
        target_accounts=target_accounts,
        force_update=args.force_update
    )
    
    # çµæœè¡¨ç¤º
    print(f"\n{'='*60}")
    print("ğŸ“Š ACCOUNT INSIGHTS COLLECTION RESULT")
    print(f"{'='*60}")
    print(f"ğŸ“… Target date: {target_date}")
    print(f"ğŸ¯ Accounts: {result.successful_accounts}/{result.total_accounts} succeeded")
    print(f"ğŸ“ Stats created: {result.stats_created}")
    print(f"âœï¸ Stats updated: {result.stats_updated}")
    print(f"ğŸ“ API calls: {result.api_calls_made}")
    
    if result.errors:
        print(f"âŒ Errors ({len(result.errors)}):")
        for error in result.errors[:5]:  # æœ€åˆã®5å€‹ã®ã‚¨ãƒ©ãƒ¼ã®ã¿è¡¨ç¤º
            print(f"   {error}")
    
    duration = (result.completed_at - result.started_at).total_seconds()
    print(f"â±ï¸ Duration: {duration:.1f}s")
    print(f"{'='*60}")
    
    # Slacké€šçŸ¥
    if args.notify_slack:
        await collector.notification.send_account_insights_result(result)
    
    # å¤±æ•—ãŒã‚ã£ãŸå ´åˆã¯ exit code 1
    return 1 if result.failed_accounts > 0 else 0

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
```

---

## ğŸ”§ å…±é€šåŸºåº•ã‚¯ãƒ©ã‚¹

### `backend/scripts/github_actions/shared/base_collector.py`

```python
"""
Base Collector Class for GitHub Actions
GitHub Actionsç”¨ã®å…±é€šåŸºåº•ã‚¯ãƒ©ã‚¹
"""

import logging
import sys
from pathlib import Path
from typing import List, Optional
from datetime import datetime
import os

from app.core.database import get_db_sync
from app.repositories.instagram_account_repository import InstagramAccountRepository

class BaseCollector:
    """GitHub Actionsç”¨ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
        self.db = None
        self.setup_logging()
        
    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        log_dir = Path(__file__).parent.parent.parent.parent / "logs" / "github_actions"
        log_dir.mkdir(parents=True, exist_ok=True)
        
        log_file = log_dir / f"{self.service_name}_{datetime.now().strftime('%Y%m%d')}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(sys.stdout),
                logging.FileHandler(log_file, encoding='utf-8')
            ]
        )
        self.logger = logging.getLogger(self.service_name)
        
    async def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šåˆæœŸåŒ–"""
        if not self.db:
            self.db = get_db_sync()
            self.logger.info("Database connection initialized")
            
    async def _cleanup_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.db:
            self.db.close()
            self.db = None
            self.logger.info("Database connection closed")
            
    async def _get_target_accounts(self, target_accounts: Optional[List[str]] = None):
        """å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—"""
        account_repo = InstagramAccountRepository(self.db)
        
        if target_accounts:
            # æŒ‡å®šã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã¿
            accounts = []
            for account_id in target_accounts:
                account = await account_repo.get_by_instagram_user_id(account_id)
                if account:
                    accounts.append(account)
                else:
                    self.logger.warning(f"Account not found: {account_id}")
        else:
            # å…¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ
            accounts = await account_repo.get_active_accounts()
            
        self.logger.info(f"Target accounts retrieved: {len(accounts)}")
        return accounts
```

---

## ğŸ“Š æ³¨æ„ç‚¹ãƒ»åˆ¶ç´„äº‹é …

### 1. APIåˆ¶é™ã¸ã®å¯¾å¿œ
```python
# ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–“ã®å¾…æ©Ÿæ™‚é–“
await asyncio.sleep(5)  # 5ç§’é–“éš”

# ãƒšãƒ¼ã‚¸ãƒ³ã‚°æ™‚ã®å¾…æ©Ÿæ™‚é–“  
await asyncio.sleep(1)  # 1ç§’é–“éš”

# æœ€å¤§APIä½¿ç”¨é‡åˆ¶å¾¡
max_pages = 20  # 1ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚ãŸã‚Šæœ€å¤§20ãƒšãƒ¼ã‚¸
```

### 2. ãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼
```python
# é‡è¤‡é˜²æ­¢
existing_stats = await daily_stats_repo.get_by_specific_date(account.id, target_date)
if existing_stats and not force_update:
    return  # ã‚¹ã‚­ãƒƒãƒ—

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
try:
    # å‡¦ç†
except Exception as e:
    # å€‹åˆ¥ã‚¨ãƒ©ãƒ¼ã§ã‚‚å…¨ä½“å‡¦ç†ã¯ç¶™ç¶š
    continue
```

### 3. ãƒ­ã‚°ãƒ»ç›£è¦–
```python
# è©³ç´°ãªå®Ÿè¡Œãƒ­ã‚°
self.logger.info(f"âœ… Collection completed in {duration:.1f}s")
self.logger.info(f"ğŸ“Š Success rate: {success_rate:.1f}%")

# Slacké€šçŸ¥
if args.notify_slack:
    await collector.notification.send_account_insights_result(result)
```

### 4. è¨­å®šç®¡ç†
```yaml
# ç’°å¢ƒå¤‰æ•°
env:
  DATABASE_URL: ${{ secrets.DATABASE_URL }}
  FACEBOOK_APP_ID: ${{ secrets.FACEBOOK_APP_ID }}
  FACEBOOK_APP_SECRET: ${{ secrets.FACEBOOK_APP_SECRET }}
  SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

---

## âœ… å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Phase 1: åŸºæœ¬å®Ÿè£…
- [ ] ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
- [ ] ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…
- [ ] å…±é€šåŸºåº•ã‚¯ãƒ©ã‚¹ä½œæˆ
- [ ] åŸºæœ¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### Phase 2: æ©Ÿèƒ½å¼·åŒ–
- [ ] é€šçŸ¥ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè£…
- [ ] è©³ç´°ãƒ­ã‚°æ©Ÿèƒ½
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- [ ] ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ä½œæˆ

### Phase 3: é‹ç”¨æº–å‚™
- [ ] æœ¬ç•ªç’°å¢ƒè¨­å®š
- [ ] ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°è¨­å®š
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´å‚™
- [ ] éšœå®³å¯¾å¿œæ‰‹é †ä½œæˆ

---

**çµè«–**: ã“ã®è¦ä»¶å®šç¾©ã«ã‚ˆã‚Šã€Instagram Daily Stats ã®å®‰å®šã—ãŸè‡ªå‹•åé›†ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚æ¯æ—¥æ±ºã¾ã£ãŸæ™‚é–“ã«å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è“„ç©ã—ã¦ã„ãã“ã¨ã§ã€é•·æœŸçš„ãªã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ†æãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚