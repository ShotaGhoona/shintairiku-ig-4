#!/usr/bin/env python3
"""
Instagram Graph API å–å¾—å¯èƒ½ãƒ‡ãƒ¼ã‚¿å®Œå…¨ç¶²ç¾…èª¿æŸ»
DBæ§‹é€ ã«æ‹˜ã‚‰ãšã€å®Ÿéš›ã«å–å¾—å¯èƒ½ãªå…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’è©³ç´°ã«ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
"""

import os
import requests
import json
from datetime import datetime, timedelta
from dotenv import load_dotenv

load_dotenv()

INSTAGRAM_USER_ID = os.getenv('INSTAGRAM_USER_ID')
ACCESS_TOKEN = os.getenv('ACCESS_TOKEN')

def get_all_available_insights_metrics():
    """åˆ©ç”¨å¯èƒ½ãªå…¨Insightsãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä½“ç³»çš„ã«èª¿æŸ»"""
    
    print("ğŸ” Instagram Insights API å…¨åˆ©ç”¨å¯èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹èª¿æŸ»")
    print("=" * 60)
    
    insights_url = f"https://graph.facebook.com/{INSTAGRAM_USER_ID}/insights"
    
    # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰å–å¾—ã—ãŸå®Ÿéš›ã«åˆ©ç”¨å¯èƒ½ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¸€è¦§
    # (å‰å›ã®æ¤œè¨¼ã§å¾—ã‚‰ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ˆã‚Š)
    confirmed_available_metrics = [
        'impressions',           # v22ä»¥é™å»ƒæ­¢ã ãŒä¸€è¦§ã«ã¯å«ã¾ã‚Œã¦ã„ã‚‹
        'reach',                 # âœ… åˆ©ç”¨å¯èƒ½ç¢ºèªæ¸ˆã¿
        'follower_count',        # âœ… åˆ©ç”¨å¯èƒ½ç¢ºèªæ¸ˆã¿
        'website_clicks',        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŒ‡å®šãŒå¿…è¦
        'profile_views',         # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŒ‡å®šãŒå¿…è¦
        'online_followers',      # æœŸé–“æŒ‡å®šã«åˆ¶é™ã‚ã‚Š
        'accounts_engaged',      # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŒ‡å®šãŒå¿…è¦
        'total_interactions',    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŒ‡å®šãŒå¿…è¦
        'likes',                 # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŒ‡å®šãŒå¿…è¦
        'comments',              # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŒ‡å®šãŒå¿…è¦
        'shares',                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŒ‡å®šãŒå¿…è¦
        'saves',                 # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŒ‡å®šãŒå¿…è¦
        'replies',               # æ–°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        'engaged_audience_demographics',    # ãƒ‡ãƒ¢ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç³»
        'reached_audience_demographics',    # ãƒ‡ãƒ¢ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç³»
        'follower_demographics',           # ãƒ‡ãƒ¢ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç³»
        'follows_and_unfollows',           # ãƒ•ã‚©ãƒ­ãƒ¼é–¢é€£
        'profile_links_taps',              # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒªãƒ³ã‚¯
        'views',                           # è¦–è´é–¢é€£
        'threads_likes',                   # Threadsé–¢é€£
        'threads_replies',                 # Threadsé–¢é€£
        'reposts',                         # Threadsé–¢é€£
        'quotes',                          # Threadsé–¢é€£
        'threads_followers',               # Threadsé–¢é€£
        'threads_follower_demographics',   # Threadsé–¢é€£
        'content_views',                   # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é–¢é€£
        'threads_views'                    # Threadsé–¢é€£
    ]
    
    today = datetime.now()
    yesterday = (today - timedelta(days=1)).strftime('%Y-%m-%d')
    today_str = today.strftime('%Y-%m-%d')
    
    # æœŸé–“è¨­å®šã®ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³
    period_tests = [
        {
            'name': 'day_period',
            'params': {
                'since': yesterday,
                'until': today_str,
                'period': 'day'
            }
        },
        {
            'name': 'lifetime_no_period',
            'params': {
                # lifetime ã®å ´åˆã¯ period ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸è¦
            }
        },
        {
            'name': 'week_period',
            'params': {
                'since': (today - timedelta(days=7)).strftime('%Y-%m-%d'),
                'until': today_str,
                'period': 'week'
            }
        }
    ]
    
    # metric_type ã®è¿½åŠ ãƒ†ã‚¹ãƒˆ
    metric_type_tests = ['total_value', 'daily_value']
    
    comprehensive_results = {}
    
    for metric in confirmed_available_metrics:
        print(f"\nğŸ“Š è©³ç´°èª¿æŸ»: {metric}")
        
        metric_results = {
            'metric_name': metric,
            'available_configurations': [],
            'successful_calls': 0,
            'best_configuration': None,
            'sample_data': None,
            'data_characteristics': {},
            'period_compatibility': {},
            'metric_type_compatibility': {}
        }
        
        # åŸºæœ¬çš„ãªæœŸé–“ãƒ†ã‚¹ãƒˆ
        for period_test in period_tests:
            period_name = period_test['name']
            base_params = period_test['params'].copy()
            
            print(f"   ğŸ—“ï¸  æœŸé–“ãƒ†ã‚¹ãƒˆ: {period_name}")
            
            # åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
            try:
                params = {
                    'metric': metric,
                    'access_token': ACCESS_TOKEN,
                    **base_params
                }
                
                response = requests.get(insights_url, params=params)
                
                if response.status_code == 200:
                    data = response.json()
                    if data.get('data') and len(data['data']) > 0:
                        metric_data = data['data'][0]
                        values = metric_data.get('values', [])
                        
                        if values:
                            config_key = f"{period_name}_basic"
                            success_info = {
                                'configuration': config_key,
                                'period_type': period_name,
                                'metric_type': 'default',
                                'params': params,
                                'data_points': len(values),
                                'sample_value': values[0].get('value'),
                                'sample_end_time': values[0].get('end_time'),
                                'metric_info': {
                                    'name': metric_data.get('name'),
                                    'title': metric_data.get('title'),
                                    'description': metric_data.get('description'),
                                    'period': metric_data.get('period')
                                }
                            }
                            
                            metric_results['available_configurations'].append(success_info)
                            metric_results['successful_calls'] += 1
                            metric_results['period_compatibility'][period_name] = True
                            
                            if not metric_results['best_configuration']:
                                metric_results['best_configuration'] = config_key
                                metric_results['sample_data'] = success_info
                            
                            print(f"     âœ… æˆåŠŸ: {len(values)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿, ã‚µãƒ³ãƒ—ãƒ«å€¤: {values[0].get('value')}")
                        else:
                            print(f"     âšª ãƒ‡ãƒ¼ã‚¿ãªã—")
                            metric_results['period_compatibility'][period_name] = 'no_data'
                    else:
                        print(f"     âšª ç©ºãƒ¬ã‚¹ãƒãƒ³ã‚¹")
                        metric_results['period_compatibility'][period_name] = 'empty'
                        
                elif response.status_code == 400:
                    error_data = response.json()
                    error_msg = error_data.get('error', {}).get('message', '')
                    
                    # metric_type ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
                    if 'metric_type=total_value' in error_msg:
                        print(f"     ğŸ”„ metric_typeå¿…è¦: total_value ã‚’è©¦è¡Œ")
                        
                        # metric_type ã‚’è¿½åŠ ã—ã¦ãƒªãƒˆãƒ©ã‚¤
                        for metric_type in metric_type_tests:
                            try:
                                retry_params = params.copy()
                                retry_params['metric_type'] = metric_type
                                
                                retry_response = requests.get(insights_url, params=retry_params)
                                
                                if retry_response.status_code == 200:
                                    retry_data = retry_response.json()
                                    if retry_data.get('data') and len(retry_data['data']) > 0:
                                        retry_metric_data = retry_data['data'][0]
                                        retry_values = retry_metric_data.get('values', [])
                                        
                                        if retry_values:
                                            config_key = f"{period_name}_{metric_type}"
                                            success_info = {
                                                'configuration': config_key,
                                                'period_type': period_name,
                                                'metric_type': metric_type,
                                                'params': retry_params,
                                                'data_points': len(retry_values),
                                                'sample_value': retry_values[0].get('value'),
                                                'sample_end_time': retry_values[0].get('end_time'),
                                                'metric_info': {
                                                    'name': retry_metric_data.get('name'),
                                                    'title': retry_metric_data.get('title'),
                                                    'description': retry_metric_data.get('description'),
                                                    'period': retry_metric_data.get('period')
                                                }
                                            }
                                            
                                            metric_results['available_configurations'].append(success_info)
                                            metric_results['successful_calls'] += 1
                                            metric_results['period_compatibility'][period_name] = True
                                            metric_results['metric_type_compatibility'][metric_type] = True
                                            
                                            if not metric_results['best_configuration']:
                                                metric_results['best_configuration'] = config_key
                                                metric_results['sample_data'] = success_info
                                            
                                            print(f"     âœ… æˆåŠŸ ({metric_type}): {len(retry_values)}ä»¶, å€¤: {retry_values[0].get('value')}")
                                            break
                                        else:
                                            print(f"     âšª ãƒ‡ãƒ¼ã‚¿ãªã— ({metric_type})")
                                
                            except Exception as e:
                                print(f"     ğŸ’¥ ä¾‹å¤– ({metric_type}): {str(e)[:30]}...")
                    
                    elif 'incompatible' in error_msg.lower():
                        print(f"     âŒ æœŸé–“éå¯¾å¿œ: {error_msg[:50]}...")
                        metric_results['period_compatibility'][period_name] = 'incompatible'
                    else:
                        print(f"     âŒ ã‚¨ãƒ©ãƒ¼: {error_msg[:50]}...")
                        metric_results['period_compatibility'][period_name] = 'error'
                else:
                    print(f"     â“ HTTP {response.status_code}")
                    metric_results['period_compatibility'][period_name] = f'http_{response.status_code}'
                    
            except Exception as e:
                print(f"     ğŸ’¥ ä¾‹å¤–: {str(e)[:50]}...")
                metric_results['period_compatibility'][period_name] = 'exception'
        
        # ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§åˆ†æ
        if metric_results['available_configurations']:
            print(f"   ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§åˆ†æ")
            
            # æœ€ã‚‚å¤šãã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’æŒã¤è¨­å®šã‚’é¸æŠ
            best_config = max(
                metric_results['available_configurations'],
                key=lambda x: x.get('data_points', 0)
            )
            
            metric_results['data_characteristics'] = {
                'max_data_points': best_config.get('data_points', 0),
                'value_type': type(best_config.get('sample_value')).__name__,
                'has_time_series': best_config.get('data_points', 0) > 1,
                'requires_metric_type': any(
                    config.get('metric_type') != 'default' 
                    for config in metric_results['available_configurations']
                ),
                'supported_periods': [
                    period for period, status in metric_results['period_compatibility'].items()
                    if status is True
                ]
            }
            
            print(f"     æœ€å¤§ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ: {metric_results['data_characteristics']['max_data_points']}")
            print(f"     å€¤ã®å‹: {metric_results['data_characteristics']['value_type']}")
            print(f"     æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿: {metric_results['data_characteristics']['has_time_series']}")
            print(f"     metric_typeå¿…è¦: {metric_results['data_characteristics']['requires_metric_type']}")
        
        comprehensive_results[metric] = metric_results
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å…¨ä½“ã®å¯ç”¨æ€§è¡¨ç¤º
        if metric_results['successful_calls'] > 0:
            print(f"   ğŸ¯ {metric}: {metric_results['successful_calls']}é€šã‚Šã®è¨­å®šã§åˆ©ç”¨å¯èƒ½")
        else:
            print(f"   âŒ {metric}: å…¨è¨­å®šã§åˆ©ç”¨ä¸å¯")
    
    return comprehensive_results

def get_all_basic_account_fields():
    """åŸºæœ¬ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å®Œå…¨èª¿æŸ»"""
    
    print(f"\n" + "=" * 60)
    print("ğŸ‘¤ åŸºæœ¬ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å®Œå…¨èª¿æŸ»")
    print("=" * 60)
    
    account_url = f"https://graph.facebook.com/{INSTAGRAM_USER_ID}"
    
    # Instagram Graph API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    potential_fields = [
        # åŸºæœ¬æƒ…å ±
        'id', 'username', 'name', 'biography', 'website',
        'profile_picture_url', 'account_type',
        
        # ã‚«ã‚¦ãƒ³ãƒˆç³»
        'media_count', 'followers_count', 'follows_count',
        
        # ãƒ“ã‚¸ãƒã‚¹æƒ…å ±
        'business_discovery', 'category', 'contact_info',
        
        # ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°
        'shopping_product_tag_eligibility', 'shopping_review_status',
        
        # ãã®ä»–
        'ig_id', 'is_private', 'is_published'
    ]
    
    field_results = {}
    
    print("åŸºæœ¬ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å€‹åˆ¥èª¿æŸ»:")
    
    # å€‹åˆ¥ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒ†ã‚¹ãƒˆ
    for field in potential_fields:
        print(f"\nğŸ“ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰èª¿æŸ»: {field}")
        
        try:
            params = {
                'fields': field,
                'access_token': ACCESS_TOKEN
            }
            
            response = requests.get(account_url, params=params)
            
            if response.status_code == 200:
                data = response.json()
                value = data.get(field)
                
                print(f"   âœ… å–å¾—æˆåŠŸ")
                print(f"   ãƒ‡ãƒ¼ã‚¿å‹: {type(value).__name__}")
                print(f"   å€¤: {str(value)[:50]}{'...' if len(str(value)) > 50 else ''}")
                
                field_results[field] = {
                    'status': 'success',
                    'value': value,
                    'data_type': type(value).__name__,
                    'value_length': len(str(value)) if value else 0,
                    'is_useful_for_daily_stats': field in [
                        'followers_count', 'follows_count', 'media_count', 
                        'username', 'name', 'account_type'
                    ]
                }
            else:
                error_data = response.json() if response.text else {}
                error_msg = error_data.get('error', {}).get('message', 'Unknown')
                print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {error_msg[:50]}...")
                
                field_results[field] = {
                    'status': 'error',
                    'error_message': error_msg,
                    'error_code': error_data.get('error', {}).get('code')
                }
                
        except Exception as e:
            print(f"   ğŸ’¥ ä¾‹å¤–: {str(e)[:50]}...")
            field_results[field] = {
                'status': 'exception',
                'error': str(e)
            }
    
    # æˆåŠŸã—ãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ä¸€æ‹¬å–å¾—ãƒ†ã‚¹ãƒˆ
    successful_fields = [
        field for field, result in field_results.items() 
        if result.get('status') == 'success'
    ]
    
    print(f"\nğŸ”„ ä¸€æ‹¬å–å¾—ãƒ†ã‚¹ãƒˆ ({len(successful_fields)}ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰)")
    
    if successful_fields:
        try:
            params = {
                'fields': ','.join(successful_fields),
                'access_token': ACCESS_TOKEN
            }
            
            response = requests.get(account_url, params=params)
            
            if response.status_code == 200:
                data = response.json()
                print(f"   âœ… ä¸€æ‹¬å–å¾—æˆåŠŸ: {len(data)}ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰")
                
                field_results['batch_fetch'] = {
                    'status': 'success',
                    'fields_count': len(data),
                    'all_data': data
                }
            else:
                print(f"   âŒ ä¸€æ‹¬å–å¾—å¤±æ•—: HTTP {response.status_code}")
                field_results['batch_fetch'] = {
                    'status': 'error',
                    'status_code': response.status_code
                }
        except Exception as e:
            print(f"   ğŸ’¥ ä¸€æ‹¬å–å¾—ä¾‹å¤–: {str(e)[:50]}...")
            field_results['batch_fetch'] = {
                'status': 'exception',
                'error': str(e)
            }
    
    return field_results

def analyze_post_data_aggregation():
    """æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã®é›†ç´„ã«ã‚ˆã‚‹æ—¥åˆ¥çµ±è¨ˆã®å¯èƒ½æ€§èª¿æŸ»"""
    
    print(f"\n" + "=" * 60)
    print("ğŸ“Š æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿é›†ç´„ã«ã‚ˆã‚‹æ—¥åˆ¥çµ±è¨ˆåˆ†æ")
    print("=" * 60)
    
    media_url = f"https://graph.facebook.com/{INSTAGRAM_USER_ID}/media"
    
    # æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é›†ç´„å¯èƒ½ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹
    print("æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ—¥åˆ¥çµ±è¨ˆã¸é›†ç´„å¯èƒ½ãªè¦ç´ :")
    
    try:
        # æœ€è¿‘ã®æŠ•ç¨¿ã‚’å–å¾—
        params = {
            'fields': 'id,timestamp,media_type,like_count,comments_count',
            'access_token': ACCESS_TOKEN,
            'limit': 50  # éå»50ä»¶ã®æŠ•ç¨¿
        }
        
        response = requests.get(media_url, params=params)
        
        if response.status_code == 200:
            data = response.json()
            posts = data.get('data', [])
            
            print(f"   ğŸ“‹ å–å¾—æŠ•ç¨¿æ•°: {len(posts)}")
            
            if posts:
                # æ—¥åˆ¥é›†ç´„åˆ†æ
                daily_aggregation = {}
                
                for post in posts:
                    timestamp = post.get('timestamp', '')
                    if timestamp:
                        # æ—¥ä»˜ã®ã¿æŠ½å‡º (YYYY-MM-DD)
                        post_date = timestamp.split('T')[0]
                        
                        if post_date not in daily_aggregation:
                            daily_aggregation[post_date] = {
                                'posts_count': 0,
                                'total_likes': 0,
                                'total_comments': 0,
                                'media_types': set()
                            }
                        
                        daily_aggregation[post_date]['posts_count'] += 1
                        daily_aggregation[post_date]['total_likes'] += post.get('like_count', 0)
                        daily_aggregation[post_date]['total_comments'] += post.get('comments_count', 0)
                        daily_aggregation[post_date]['media_types'].add(post.get('media_type', 'unknown'))
                
                print(f"\n   ğŸ“ˆ æ—¥åˆ¥é›†ç´„çµæœ (æœ€è¿‘{len(daily_aggregation)}æ—¥åˆ†):")
                
                aggregation_results = {}
                
                for date, stats in sorted(daily_aggregation.items(), reverse=True)[:7]:  # æœ€æ–°7æ—¥åˆ†è¡¨ç¤º
                    media_types_list = list(stats['media_types'])
                    print(f"     ğŸ“… {date}:")
                    print(f"       æŠ•ç¨¿æ•°: {stats['posts_count']}")
                    print(f"       ã„ã„ã­åˆè¨ˆ: {stats['total_likes']}")
                    print(f"       ã‚³ãƒ¡ãƒ³ãƒˆåˆè¨ˆ: {stats['total_comments']}")
                    print(f"       ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—: {', '.join(media_types_list)}")
                    
                    aggregation_results[date] = {
                        'posts_count': stats['posts_count'],
                        'total_likes': stats['total_likes'],
                        'total_comments': stats['total_comments'],
                        'media_types': media_types_list,
                        'avg_likes_per_post': stats['total_likes'] / stats['posts_count'] if stats['posts_count'] > 0 else 0,
                        'avg_comments_per_post': stats['total_comments'] / stats['posts_count'] if stats['posts_count'] > 0 else 0
                    }
                
                # é›†ç´„ã®å¯èƒ½æ€§è©•ä¾¡
                potential_daily_metrics = {
                    'daily_posts_count': 'æ—¥åˆ¥æŠ•ç¨¿æ•°',
                    'daily_total_likes': 'æ—¥åˆ¥ã„ã„ã­åˆè¨ˆ',
                    'daily_total_comments': 'æ—¥åˆ¥ã‚³ãƒ¡ãƒ³ãƒˆåˆè¨ˆ',
                    'daily_avg_likes_per_post': 'æ—¥åˆ¥æŠ•ç¨¿ã‚ãŸã‚Šå¹³å‡ã„ã„ã­æ•°',
                    'daily_avg_comments_per_post': 'æ—¥åˆ¥æŠ•ç¨¿ã‚ãŸã‚Šå¹³å‡ã‚³ãƒ¡ãƒ³ãƒˆæ•°',
                    'daily_media_type_distribution': 'æ—¥åˆ¥ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—åˆ†å¸ƒ'
                }
                
                print(f"\n   ğŸ¯ æŠ•ç¨¿é›†ç´„ã§ä½œæˆå¯èƒ½ãªæ—¥åˆ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
                for metric_key, description in potential_daily_metrics.items():
                    print(f"     âœ… {metric_key}: {description}")
                
                return {
                    'status': 'success',
                    'daily_aggregation_sample': aggregation_results,
                    'potential_metrics': potential_daily_metrics,
                    'data_availability': {
                        'posts_analyzed': len(posts),
                        'date_range_days': len(daily_aggregation),
                        'can_create_time_series': len(daily_aggregation) > 1
                    }
                }
            else:
                print("   âŒ æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ãªã—")
                return {'status': 'no_posts'}
        else:
            print(f"   âŒ æŠ•ç¨¿å–å¾—å¤±æ•—: HTTP {response.status_code}")
            return {'status': 'error', 'status_code': response.status_code}
            
    except Exception as e:
        print(f"   ğŸ’¥ ä¾‹å¤–: {str(e)}")
        return {'status': 'exception', 'error': str(e)}

def generate_comprehensive_summary(insights_results, fields_results, aggregation_results):
    """åŒ…æ‹¬çš„ãªåˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
    
    print(f"\n" + "=" * 60)
    print("ğŸ“‹ å–å¾—å¯èƒ½ãƒ‡ãƒ¼ã‚¿å®Œå…¨ã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    
    # Insights API ã‚µãƒãƒªãƒ¼
    available_insights = [
        metric for metric, result in insights_results.items()
        if result.get('successful_calls', 0) > 0
    ]
    
    insights_by_category = {
        'ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼é–¢é€£': ['follower_count', 'follows_and_unfollows', 'follower_demographics'],
        'ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆé–¢é€£': ['likes', 'comments', 'shares', 'saves', 'total_interactions'],
        'ãƒªãƒ¼ãƒãƒ»è¦–è´é–¢é€£': ['reach', 'views', 'content_views'],
        'ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æ´»å‹•': ['profile_views', 'website_clicks', 'profile_links_taps'],
        'ãƒ‡ãƒ¢ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯': ['engaged_audience_demographics', 'reached_audience_demographics'],
        'Threadsé–¢é€£': ['threads_likes', 'threads_replies', 'threads_followers', 'threads_views'],
        'ãã®ä»–': ['online_followers', 'replies', 'reposts', 'quotes']
    }
    
    print("ğŸ¯ Instagram Insights API åˆ©ç”¨å¯èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
    
    total_available_insights = 0
    categorized_available = {}
    
    for category, metrics in insights_by_category.items():
        available_in_category = [m for m in metrics if m in available_insights]
        if available_in_category:
            print(f"\n   ğŸ“Š {category} ({len(available_in_category)}å€‹):")
            categorized_available[category] = []
            
            for metric in available_in_category:
                result = insights_results[metric]
                best_config = result.get('best_configuration', 'N/A')
                data_points = result.get('data_characteristics', {}).get('max_data_points', 0)
                requires_metric_type = result.get('data_characteristics', {}).get('requires_metric_type', False)
                
                config_note = f"({best_config}"
                if requires_metric_type:
                    config_note += ", metric_typeå¿…è¦"
                config_note += ")"
                
                print(f"     âœ… {metric}: {data_points}pts {config_note}")
                
                categorized_available[category].append({
                    'metric': metric,
                    'max_data_points': data_points,
                    'best_configuration': best_config,
                    'requires_metric_type': requires_metric_type,
                    'configurations_count': result.get('successful_calls', 0)
                })
                
                total_available_insights += 1
    
    # åŸºæœ¬ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚µãƒãƒªãƒ¼
    available_fields = [
        field for field, result in fields_results.items()
        if result.get('status') == 'success' and field != 'batch_fetch'
    ]
    
    print(f"\nğŸ·ï¸  åŸºæœ¬ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ ({len(available_fields)}å€‹):")
    
    field_categories = {
        'è­˜åˆ¥æƒ…å ±': ['id', 'username', 'name', 'ig_id'],
        'æ•°å€¤ãƒ‡ãƒ¼ã‚¿': ['media_count', 'followers_count', 'follows_count'],
        'ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±': ['biography', 'website', 'profile_picture_url'],
        'ãƒ“ã‚¸ãƒã‚¹æƒ…å ±': ['account_type', 'category', 'contact_info'],
        'ãã®ä»–': []
    }
    
    for field in available_fields:
        categorized = False
        for category, category_fields in field_categories.items():
            if field in category_fields:
                categorized = True
                break
        if not categorized:
            field_categories['ãã®ä»–'].append(field)
    
    for category, fields in field_categories.items():
        category_available = [f for f in fields if f in available_fields]
        if category_available:
            print(f"   ğŸ“ {category}: {', '.join(category_available)}")
    
    # æŠ•ç¨¿é›†ç´„ã‚µãƒãƒªãƒ¼
    if aggregation_results.get('status') == 'success':
        potential_metrics = aggregation_results.get('potential_metrics', {})
        data_info = aggregation_results.get('data_availability', {})
        
        print(f"\nğŸ“ˆ æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿é›†ç´„ã«ã‚ˆã‚‹æ—¥åˆ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹ ({len(potential_metrics)}å€‹):")
        print(f"   ğŸ“‹ åˆ†æå¯èƒ½æŠ•ç¨¿æ•°: {data_info.get('posts_analyzed', 0)}")
        print(f"   ğŸ“… æ—¥ä»˜ç¯„å›²: {data_info.get('date_range_days', 0)}æ—¥åˆ†")
        print(f"   ğŸ”„ æ™‚ç³»åˆ—ä½œæˆå¯èƒ½: {'Yes' if data_info.get('can_create_time_series') else 'No'}")
        
        for metric_key, description in potential_metrics.items():
            print(f"   âœ… {metric_key}: {description}")
    
    # ç·åˆè©•ä¾¡
    print(f"\n" + "ğŸ‰" * 20)
    print("ğŸ“Š å–å¾—å¯èƒ½ãƒ‡ãƒ¼ã‚¿ç·åˆè©•ä¾¡")
    print("ğŸ‰" * 20)
    
    print(f"âœ… Insights API ãƒ¡ãƒˆãƒªã‚¯ã‚¹: {total_available_insights}å€‹")
    print(f"âœ… åŸºæœ¬ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {len(available_fields)}å€‹")
    
    if aggregation_results.get('status') == 'success':
        aggregation_metrics_count = len(aggregation_results.get('potential_metrics', {}))
        print(f"âœ… æŠ•ç¨¿é›†ç´„ãƒ¡ãƒˆãƒªã‚¯ã‚¹: {aggregation_metrics_count}å€‹")
        total_metrics = total_available_insights + len(available_fields) + aggregation_metrics_count
    else:
        print(f"âŒ æŠ•ç¨¿é›†ç´„ãƒ¡ãƒˆãƒªã‚¯ã‚¹: åˆ©ç”¨ä¸å¯")
        total_metrics = total_available_insights + len(available_fields)
    
    print(f"ğŸ¯ åˆè¨ˆåˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿è¦ç´ : {total_metrics}å€‹")
    
    # å®Ÿè£…æ¨å¥¨äº‹é …
    print(f"\nğŸ’¡ å®Ÿè£…æ¨å¥¨äº‹é …:")
    print(f"   ğŸ”„ æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿åé›†ã«æœ€é©: {len([m for m in available_insights if 'follower_count' in m or 'reach' in m])}å€‹ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹")
    print(f"   ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºå¯èƒ½: å…¨{total_metrics}è¦ç´ ")
    print(f"   ğŸ“ˆ æ™‚ç³»åˆ—åˆ†æå¯èƒ½: Insights API + æŠ•ç¨¿é›†ç´„")
    
    return {
        'insights_metrics': categorized_available,
        'basic_fields': available_fields,
        'aggregation_metrics': aggregation_results.get('potential_metrics', {}),
        'total_available_elements': total_metrics,
        'implementation_readiness': 'high' if total_metrics > 20 else 'medium' if total_metrics > 10 else 'low'
    }

def save_comprehensive_results(insights_results, fields_results, aggregation_results, summary):
    """åŒ…æ‹¬çš„çµæœã‚’ä¿å­˜"""
    
    output_dir = "output-json"
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # åŒ…æ‹¬çš„çµæœ
    comprehensive_data = {
        'analysis_date': datetime.now().isoformat(),
        'instagram_user_id': INSTAGRAM_USER_ID,
        'insights_api_analysis': insights_results,
        'basic_fields_analysis': fields_results,
        'post_aggregation_analysis': aggregation_results,
        'comprehensive_summary': summary,
        'metadata': {
            'total_insights_tested': len(insights_results),
            'available_insights': len([r for r in insights_results.values() if r.get('successful_calls', 0) > 0]),
            'total_fields_tested': len([f for f in fields_results.keys() if f != 'batch_fetch']),
            'available_fields': len([r for r in fields_results.values() if r.get('status') == 'success' and isinstance(r, dict)]),
            'aggregation_feasible': aggregation_results.get('status') == 'success'
        }
    }
    
    # ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«
    main_file = f"{output_dir}/04_comprehensive_available_data_{timestamp}.json"
    with open(main_file, 'w', encoding='utf-8') as f:
        json.dump(comprehensive_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ åŒ…æ‹¬çš„åˆ†æçµæœã‚’ä¿å­˜: {main_file}")
    
    # å®Ÿè£…ã‚¬ã‚¤ãƒ‰å°‚ç”¨ãƒ•ã‚¡ã‚¤ãƒ«
    implementation_guide = {
        'analysis_date': datetime.now().isoformat(),
        'available_data_elements': summary['total_available_elements'],
        'implementation_readiness': summary['implementation_readiness'],
        'recommended_daily_collection': {
            'insights_api': [
                metric for metric in insights_results.keys()
                if insights_results[metric].get('successful_calls', 0) > 0 and
                   any(period in insights_results[metric].get('period_compatibility', {})
                       for period in ['day_period'])
            ],
            'basic_fields': [
                field for field in fields_results.keys()
                if fields_results[field].get('status') == 'success' and field != 'batch_fetch' and
                   fields_results[field].get('is_useful_for_daily_stats', False)
            ],
            'post_aggregation': list(aggregation_results.get('potential_metrics', {}).keys()) if aggregation_results.get('status') == 'success' else []
        },
        'api_call_strategy': {
            'insights_frequency': 'daily',
            'basic_fields_frequency': 'daily',
            'post_aggregation_frequency': 'daily',
            'recommended_collection_time': 'early_morning_jst'
        }
    }
    
    guide_file = f"{output_dir}/04_implementation_ready_data_guide_{timestamp}.json"
    with open(guide_file, 'w', encoding='utf-8') as f:
        json.dump(implementation_guide, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ å®Ÿè£…ã‚¬ã‚¤ãƒ‰ã‚’ä¿å­˜: {guide_file}")
    
    return main_file, guide_file

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    if not all([INSTAGRAM_USER_ID, ACCESS_TOKEN]):
        print("âŒ ç’°å¢ƒå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
        exit(1)
    
    print("ğŸš€ Instagram API å–å¾—å¯èƒ½ãƒ‡ãƒ¼ã‚¿å®Œå…¨èª¿æŸ»ã‚’é–‹å§‹ã—ã¾ã™...")
    print("ğŸ“‹ DBæ§‹é€ ã«æ‹˜ã‚‰ãšã€å®Ÿéš›ã«å–å¾—å¯èƒ½ãªå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»")
    
    try:
        # 1. Insights API å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹èª¿æŸ»
        print("\n" + "ğŸ¯" * 20)
        insights_results = get_all_available_insights_metrics()
        
        # 2. åŸºæœ¬ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å®Œå…¨èª¿æŸ»
        print("\n" + "ğŸ¯" * 20)
        fields_results = get_all_basic_account_fields()
        
        # 3. æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿é›†ç´„åˆ†æ
        print("\n" + "ğŸ¯" * 20)
        aggregation_results = analyze_post_data_aggregation()
        
        # 4. åŒ…æ‹¬çš„ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
        print("\n" + "ğŸ¯" * 20)
        summary = generate_comprehensive_summary(insights_results, fields_results, aggregation_results)
        
        # 5. çµæœä¿å­˜
        print("\n" + "=" * 60)
        main_file, guide_file = save_comprehensive_results(
            insights_results, fields_results, aggregation_results, summary
        )
        
        print(f"\n" + "ğŸ‰" * 30)
        print("âœ… Instagram API å–å¾—å¯èƒ½ãƒ‡ãƒ¼ã‚¿å®Œå…¨èª¿æŸ»å®Œäº†!")
        print(f"ğŸ“ è©³ç´°çµæœ: {main_file}")
        print(f"ğŸ“ å®Ÿè£…ã‚¬ã‚¤ãƒ‰: {guide_file}")
        print("ğŸ“Š ã“ã‚Œã§å®Ÿéš›ã«å–å¾—å¯èƒ½ãªå…¨ãƒ‡ãƒ¼ã‚¿ãŒåˆ¤æ˜ã—ã¾ã—ãŸï¼")
        print("ğŸ‰" * 30)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ èª¿æŸ»ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)