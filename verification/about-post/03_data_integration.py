#!/usr/bin/env python3
"""
Phase 3: ãƒ‡ãƒ¼ã‚¿çµ±åˆæ¤œè¨¼
æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’çµ±åˆã—ã¦DBæ§‹é€ ã«é©åˆã™ã‚‹ã‹ã‚’æ¤œè¨¼
ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã®è¨ˆç®—ã‚„ãƒ‡ãƒ¼ã‚¿å‹ã®é©åˆæ€§ã‚’ç¢ºèª
"""

import os
import json
from datetime import datetime
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

def load_previous_data():
    """å‰ã®Phaseã§ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    try:
        # æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        with open('posts_table_sample.json', 'r', encoding='utf-8') as f:
            posts_data = json.load(f)
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        with open('post_metrics_table_sample.json', 'r', encoding='utf-8') as f:
            metrics_data = json.load(f)
        
        return posts_data, metrics_data
        
    except FileNotFoundError as e:
        print(f"âŒ å‰ã®Phaseã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
        print("å…ˆã« 01_get_posts_data.py ã¨ 02_get_post_metrics.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return None, None

def validate_data_types(posts_data, metrics_data):
    """ãƒ‡ãƒ¼ã‚¿å‹ã®é©åˆæ€§ã‚’æ¤œè¨¼"""
    
    print("ğŸ” ãƒ‡ãƒ¼ã‚¿å‹æ¤œè¨¼:")
    print("-" * 20)
    
    validation_results = {
        'posts': {'valid': 0, 'invalid': 0, 'issues': []},
        'metrics': {'valid': 0, 'invalid': 0, 'issues': []}
    }
    
    # postsãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿å‹æ¤œè¨¼
    posts_schema = {
        'instagram_post_id': str,
        'media_type': str,
        'caption': (str, type(None)),
        'media_url': (str, type(None)),
        'posted_at': str,
        'thumbnail_url': (str, type(None)),
        'permalink': (str, type(None))
    }
    
    print("ğŸ“ postsãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿å‹æ¤œè¨¼:")
    for i, post in enumerate(posts_data):
        valid = True
        for field, expected_type in posts_schema.items():
            value = post.get(field)
            if isinstance(expected_type, tuple):
                # è¤‡æ•°ã®å‹ã‚’è¨±å¯ï¼ˆä¾‹ï¼šstr or Noneï¼‰
                if not isinstance(value, expected_type):
                    validation_results['posts']['issues'].append(
                        f"æŠ•ç¨¿{i+1}: {field} ã®å‹ãŒä¸æ­£ (æœŸå¾…: {expected_type}, å®Ÿéš›: {type(value)})"
                    )
                    valid = False
            else:
                # å˜ä¸€ã®å‹ã®ã¿è¨±å¯
                if not isinstance(value, expected_type):
                    validation_results['posts']['issues'].append(
                        f"æŠ•ç¨¿{i+1}: {field} ã®å‹ãŒä¸æ­£ (æœŸå¾…: {expected_type}, å®Ÿéš›: {type(value)})"
                    )
                    valid = False
        
        if valid:
            validation_results['posts']['valid'] += 1
        else:
            validation_results['posts']['invalid'] += 1
    
    print(f"  âœ… æœ‰åŠ¹: {validation_results['posts']['valid']}ä»¶")
    print(f"  âŒ ç„¡åŠ¹: {validation_results['posts']['invalid']}ä»¶")
    
    # post_metricsãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿å‹æ¤œè¨¼
    metrics_schema = {
        'post_id': str,
        'likes': int,
        'comments': int,
        'saves': int,
        'shares': int,
        'views': int,
        'reach': int,
        'impressions': int,
        'engagement_rate': (int, float),
        'recorded_at': str
    }
    
    print("\nğŸ“Š post_metricsãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿å‹æ¤œè¨¼:")
    for i, metric in enumerate(metrics_data):
        valid = True
        for field, expected_type in metrics_schema.items():
            value = metric.get(field)
            if isinstance(expected_type, tuple):
                if not isinstance(value, expected_type):
                    validation_results['metrics']['issues'].append(
                        f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹{i+1}: {field} ã®å‹ãŒä¸æ­£ (æœŸå¾…: {expected_type}, å®Ÿéš›: {type(value)})"
                    )
                    valid = False
            else:
                if not isinstance(value, expected_type):
                    validation_results['metrics']['issues'].append(
                        f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹{i+1}: {field} ã®å‹ãŒä¸æ­£ (æœŸå¾…: {expected_type}, å®Ÿéš›: {type(value)})"
                    )
                    valid = False
        
        if valid:
            validation_results['metrics']['valid'] += 1
        else:
            validation_results['metrics']['invalid'] += 1
    
    print(f"  âœ… æœ‰åŠ¹: {validation_results['metrics']['valid']}ä»¶")
    print(f"  âŒ ç„¡åŠ¹: {validation_results['metrics']['invalid']}ä»¶")
    
    return validation_results

def calculate_engagement_rates(metrics_data):
    """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã®è¨ˆç®—æ¤œè¨¼"""
    
    print("\nğŸ“ˆ ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡è¨ˆç®—æ¤œè¨¼:")
    print("-" * 30)
    
    calculation_results = []
    
    for i, metric in enumerate(metrics_data):
        likes = metric.get('likes', 0)
        comments = metric.get('comments', 0)
        saves = metric.get('saves', 0)
        shares = metric.get('shares', 0)
        reach = metric.get('reach', 0)
        
        # æ‰‹å‹•è¨ˆç®—
        if reach > 0:
            total_engagement = likes + comments + saves + shares
            calculated_rate = (total_engagement / reach) * 100
        else:
            calculated_rate = 0.0
        
        # APIã‹ã‚‰å–å¾—ã—ãŸå€¤
        api_rate = metric.get('engagement_rate', 0)
        
        # å·®ç•°ã®ç¢ºèªï¼ˆå°æ•°ç‚¹ä»¥ä¸‹ã®èª¤å·®ã‚’è€ƒæ…®ï¼‰
        difference = abs(calculated_rate - api_rate)
        is_consistent = difference < 0.1  # 0.1%ä»¥å†…ã®èª¤å·®ã¯è¨±å®¹
        
        result = {
            'post_index': i + 1,
            'post_id': metric.get('post_id'),
            'likes': likes,
            'comments': comments,
            'saves': saves,
            'shares': shares,
            'reach': reach,
            'total_engagement': likes + comments + saves + shares,
            'calculated_rate': round(calculated_rate, 2),
            'api_rate': api_rate,
            'difference': round(difference, 2),
            'is_consistent': is_consistent
        }
        
        calculation_results.append(result)
        
        print(f"æŠ•ç¨¿{i+1}:")
        print(f"  ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ: {result['total_engagement']} / ãƒªãƒ¼ãƒ: {reach}")
        print(f"  è¨ˆç®—å€¤: {result['calculated_rate']}%")
        print(f"  APIå€¤: {result['api_rate']}%")
        print(f"  å·®ç•°: {result['difference']}% {'âœ…' if is_consistent else 'âŒ'}")
    
    # çµ±è¨ˆæƒ…å ±
    consistent_count = sum(1 for r in calculation_results if r['is_consistent'])
    total_count = len(calculation_results)
    consistency_rate = (consistent_count / total_count) * 100 if total_count > 0 else 0
    
    print(f"\nä¸€è²«æ€§: {consistent_count}/{total_count} ({consistency_rate:.1f}%)")
    
    return calculation_results

def create_integrated_dataset(posts_data, metrics_data):
    """æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’çµ±åˆã—ã¦ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
    
    print("\nğŸ”— ãƒ‡ãƒ¼ã‚¿çµ±åˆ:")
    print("-" * 15)
    
    integrated_data = []
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’post_idã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
    metrics_by_post_id = {metric['post_id']: metric for metric in metrics_data}
    
    for post in posts_data:
        post_id = post.get('instagram_post_id')
        metrics = metrics_by_post_id.get(post_id)
        
        if metrics:
            # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ã®çµ±åˆãƒ‡ãƒ¼ã‚¿
            integrated_item = {
                'id': post_id,
                'date': post.get('posted_at', '').split('T')[0] if post.get('posted_at') else '',
                'thumbnail': post.get('media_url', ''),
                'type': map_media_type(post.get('media_type')),
                'reach': metrics.get('reach', 0),
                'likes': metrics.get('likes', 0),
                'comments': metrics.get('comments', 0),
                'shares': metrics.get('shares', 0),
                'saves': metrics.get('saves', 0),
                'views': metrics.get('views', 0),
                'impressions': metrics.get('impressions', 0),
                'engagement_rate': metrics.get('engagement_rate', 0.0),
                'caption': post.get('caption', ''),
                'media_url': post.get('media_url', ''),
                'permalink': post.get('permalink', '')
            }
            
            integrated_data.append(integrated_item)
            
            print(f"âœ… çµ±åˆæˆåŠŸ: {post_id}")
        else:
            print(f"âŒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹æœªå–å¾—: {post_id}")
    
    print(f"\nçµ±åˆçµæœ: {len(integrated_data)}/{len(posts_data)} ä»¶")
    
    return integrated_data

def map_media_type(api_media_type):
    """APIã®media_typeã‚’ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ã®å½¢å¼ã«ãƒãƒƒãƒ”ãƒ³ã‚°"""
    mapping = {
        'IMAGE': 'Feed',
        'VIDEO': 'Feed',  # ã“ã“ã¯Reelsã‹Feedã‹ã®åˆ¤å®šãŒå¿…è¦
        'CAROUSEL_ALBUM': 'Feed',
        'STORY': 'Story'
    }
    return mapping.get(api_media_type, 'Feed')

def data_integration_verification():
    """ãƒ‡ãƒ¼ã‚¿çµ±åˆæ¤œè¨¼ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    print("=" * 50)
    print("Phase 3: ãƒ‡ãƒ¼ã‚¿çµ±åˆæ¤œè¨¼")
    print("=" * 50)
    
    # å‰ã®Phaseã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    posts_data, metrics_data = load_previous_data()
    if not posts_data or not metrics_data:
        return False
    
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:")
    print(f"  æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿: {len(posts_data)}ä»¶")
    print(f"  ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿: {len(metrics_data)}ä»¶")
    
    # ãƒ‡ãƒ¼ã‚¿å‹æ¤œè¨¼
    validation_results = validate_data_types(posts_data, metrics_data)
    
    # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡è¨ˆç®—æ¤œè¨¼
    calculation_results = calculate_engagement_rates(metrics_data)
    
    # ãƒ‡ãƒ¼ã‚¿çµ±åˆ
    integrated_data = create_integrated_dataset(posts_data, metrics_data)
    
    # çµæœã®ä¿å­˜
    results = {
        'validation_results': validation_results,
        'calculation_results': calculation_results,
        'integrated_data': integrated_data,
        'summary': {
            'posts_count': len(posts_data),
            'metrics_count': len(metrics_data),
            'integrated_count': len(integrated_data),
            'data_integrity': len(integrated_data) / len(posts_data) * 100 if posts_data else 0
        }
    }
    
    output_file = 'data_integration_results.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ çµ±åˆæ¤œè¨¼çµæœã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
    frontend_file = 'frontend_compatible_data.json'
    with open(frontend_file, 'w', encoding='utf-8') as f:
        json.dump(integrated_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ¨ ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ {frontend_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    # æ¤œè¨¼çµæœã®ã‚µãƒãƒªãƒ¼
    print("\nğŸ“‹ çµ±åˆæ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼:")
    print("-" * 25)
    print(f"æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿å–å¾—ç‡: {len(posts_data)}/{len(posts_data)} (100%)")
    print(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ç‡: {len(metrics_data)}/{len(posts_data)} ({len(metrics_data)/len(posts_data)*100:.1f}%)")
    print(f"ãƒ‡ãƒ¼ã‚¿çµ±åˆç‡: {len(integrated_data)}/{len(posts_data)} ({results['summary']['data_integrity']:.1f}%)")
    
    validation_success = (
        validation_results['posts']['invalid'] == 0 and 
        validation_results['metrics']['invalid'] == 0
    )
    
    if validation_success and len(integrated_data) > 0:
        print("âœ… çµ±åˆæ¤œè¨¼æˆåŠŸ: DBæ§‹é€ ã¨API ãƒ‡ãƒ¼ã‚¿ãŒé©åˆã—ã¦ã„ã¾ã™")
        return True
    else:
        print("âŒ çµ±åˆæ¤œè¨¼å¤±æ•—: DBæ§‹é€ ã®è¦‹ç›´ã—ãŒå¿…è¦ã§ã™")
        return False

if __name__ == "__main__":
    success = data_integration_verification()
    
    if success:
        print("\n" + "=" * 50)
        print("Phase 3 å®Œäº†: ãƒ‡ãƒ¼ã‚¿çµ±åˆæ¤œè¨¼ âœ…")
        print("=" * 50)
        print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: 04_response_analysis.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
    else:
        print("\n" + "=" * 50)
        print("Phase 3 å¤±æ•—: ãƒ‡ãƒ¼ã‚¿çµ±åˆæ¤œè¨¼ âŒ")
        print("=" * 50)